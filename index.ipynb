{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter analysis for social unrest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Displaying data as dataframe\n",
    "#pd.read_csv reads a comma-separated values (csv) file into dataframe.\n",
    "trainingData = pd.read_csv(\"tweets.csv\")\n",
    "\n",
    "#Displaying certain columns from the dataframe to display - \n",
    "# df.loc accesses a group of rows and columns by label(s) from dataframe.\n",
    "trainingData = trainingData.loc[:100,[ 'text', 'target']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping duplicate tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing duplicates from the dataframe\n",
    "def remove_duplicate_tweets(dataframe):\n",
    "#     pd.DataFrame.drop_duplicates - returns DataFrame with duplicate rows removed.\n",
    "    dataframe.drop_duplicates(subset=['text'])\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping empty tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Removing empty tweets from the dataframe\n",
    "def remove_empty_tweets(dataframe):\n",
    "    # pd.DataFrame.dropna - removes missing tweets.\n",
    "    dataframe.dropna(subset = ['text'], inplace = True)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting tweets to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting tweet text to lowercase for tokenization\n",
    "def convert_to_lowercase(dataframe):\n",
    "    for index, val in dataframe.iterrows():\n",
    "        dataframe.at[index,'text'] = val['text'].lower()\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove hyperlinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove hyperlinks from the tweet text\n",
    "def remove_hyperlinks(dataframe):\n",
    "    for index, val in dataframe.iterrows():\n",
    "        processed_tweet = ''\n",
    "        words = val['text'].split(' ')\n",
    "        for word in words:\n",
    "            if 'http' not in word:\n",
    "                processed_tweet += f'{word} '\n",
    "        dataframe.at[index,'text'] = processed_tweet\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_hashtags(dataframe):\n",
    "    for index, val in dataframe.iterrows():\n",
    "        processed_tweet = ''\n",
    "        words = val['text'].split(' ')\n",
    "        for word in words:\n",
    "            if '#' not in word:\n",
    "                processed_tweet += f'{word} '\n",
    "        dataframe.at[index,'text'] = processed_tweet\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def tokenize_words(dataframe):\n",
    "    for index, val in dataframe.iterrows():\n",
    "         words = word_tokenize(val['text'])\n",
    "         words = filter(lambda x: len(x) > 2, words)\n",
    "         dataframe.at[index,'text'] = ' '.join(words)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "def remove_stopwords(dataframe):\n",
    "    stopwords_array = stopwords.words('english')\n",
    "    for index, val in dataframe.iterrows():\n",
    "        text = []\n",
    "        words = val['text'].split(' ')\n",
    "        for word in words:\n",
    "            if word not in stopwords_array:\n",
    "                text.append(word)\n",
    "        dataframe.at[index,'text'] = ' '.join(text)   \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "def stemming(dataframe):\n",
    "    stemmer = PorterStemmer()\n",
    "    for index, val in dataframe.iterrows():\n",
    "        words = val['text'].split(' ')\n",
    "        \n",
    "        text = [stemmer.stem(word) for word in words]  \n",
    "        dataframe.at[index,'text'] = ' '.join(text)\n",
    "        \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>commun violenc bhainsa, telangana. \"stone pelt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>telangana: section 144 impo bhainsa januari 13...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arsonist set car ablaz dealership</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arsonist set car ablaz dealership</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"lord jesus, love bring freedom pardon. fill h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  commun violenc bhainsa, telangana. \"stone pelt...       1\n",
       "1  telangana: section 144 impo bhainsa januari 13...       1\n",
       "2              arsonist set car ablaz dealership           1\n",
       "3              arsonist set car ablaz dealership           1\n",
       "4  \"lord jesus, love bring freedom pardon. fill h...       0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData = remove_duplicate_tweets(trainingData)\n",
    "trainingData = remove_empty_tweets(trainingData)\n",
    "trainingData = convert_to_lowercase(trainingData)\n",
    "trainingData = remove_hyperlinks(trainingData)\n",
    "trainingData = remove_hashtags(trainingData)\n",
    "\n",
    "trainingData.reset_index(inplace = True)\n",
    "trainingData.drop(['index'], axis = 1, inplace = True)\n",
    "trainingData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@0x49fa98 @fahadmalam are ancaps that protest ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(now: counter-protesting non-violent protest a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@philippinestar @paolosromero the pen is might...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>modi ji it’s time you start being honest with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(now: counter-protesting non-violent protest a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  @0x49fa98 @fahadmalam are ancaps that protest ...\n",
       "1  (now: counter-protesting non-violent protest a...\n",
       "2  @philippinestar @paolosromero the pen is might...\n",
       "3  modi ji it’s time you start being honest with ...\n",
       "4  (now: counter-protesting non-violent protest a..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData = pd.read_csv(\"data/protest.csv\")\n",
    "testData = testData.loc[:, ['text']]\n",
    "testData = remove_duplicate_tweets(testData)\n",
    "testData = remove_empty_tweets(testData)\n",
    "testData = convert_to_lowercase(testData)\n",
    "testData = remove_hyperlinks(testData)\n",
    "testData = remove_hashtags(testData)\n",
    "\n",
    "testData.reset_index(inplace = True)\n",
    "testData.drop(['index'], axis = 1, inplace = True)\n",
    "testData.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
